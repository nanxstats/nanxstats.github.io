<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>serialization on Nan Xiao | 肖楠</title>
    <link>https://nanx.me/tags/serialization/</link>
    <description>Recent content in serialization on Nan Xiao | 肖楠</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 01 May 2022 20:00:00 +0000</lastBuildDate><atom:link href="https://nanx.me/tags/serialization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Honey, I Serialized the Data</title>
      <link>https://nanx.me/blog/post/r-serialize-timemachine/</link>
      <pubDate>Sun, 01 May 2022 20:00:00 +0000</pubDate>
      
      <guid>https://nanx.me/blog/post/r-serialize-timemachine/</guid>
      <description>The R code to reproduce the results in this post is available from https://github.com/nanxstats/r-serialize-timemachine.
Photo by Alex Gogan.
A mystery on serialize() Serialization/deserialization is an important topic for exchanging data efficiently at scale. In R, there is a native choice for this: serialize()/unserialize() and their more convenient interface saveRDS()/readRDS().
Yihui once asked why the first 14 bytes in R serialized data were skipped in digest::digest(), instead of the first 17 bytes for the binary format, as the additional three filling zero-bytes are always there.</description>
    </item>
    
  </channel>
</rss>
