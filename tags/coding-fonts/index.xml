<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>coding fonts on Nan Xiao | 肖楠</title>
    <link>https://nanx.me/tags/coding-fonts/</link>
    <description>Recent content in coding fonts on Nan Xiao | 肖楠</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 19 Jun 2024 03:30:00 +0000</lastBuildDate>
    <atom:link href="https://nanx.me/tags/coding-fonts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>You should (maybe) enable font ligatures when building with GPT models</title>
      <link>https://nanx.me/blog/post/gpt-models-font-ligatures/</link>
      <pubDate>Wed, 19 Jun 2024 03:30:00 +0000</pubDate>
      <guid>https://nanx.me/blog/post/gpt-models-font-ligatures/</guid>
      <description>Parts of a typewriter. Photo by Florian Klauer. The token &amp;lt;|endoftext|&amp;gt; is a special token used as a document separator for OpenAI GPT models. It has become quite prevalent if you look closely:&#xA;It has been used since GPT-2 and remains present in the OpenAI API for their latest models. Their tokenizer package, tiktoken, includes logic to process text with these special tokens. The markup &amp;lt;| and |&amp;gt; is widely used in the code bases of LangChain and text-generation-webui.</description>
    </item>
  </channel>
</rss>
