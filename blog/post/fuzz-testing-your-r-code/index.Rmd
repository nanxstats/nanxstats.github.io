---
title: Fuzz Testing Your R Code
author: "Nan Xiao"
date: "2020-09-28T22:30:00"
slug: fuzz-testing-your-r-code
categories: []
tags:
  - R
  - fuzz testing
meta_img: image/log-book-with-computer-bug.jpg
description: "Fuzz testing is an alternative approach for validating the robustness of your R code."
---

```{r, include=FALSE}
knitr::opts_chunk$set(comment = "#>", collapse = TRUE, echo = TRUE, message = FALSE)
options(width = 70)
```

Good software requires even better testing. Particularly, [unit testing](https://r-pkgs.org/tests.html) has been widely used by many R packages as a tool for reducing the number of bugs and improving code structure. A unit test is often written when a single unit of functionality is created in the program. Is there a good way to test a large program or system after it is created? The answer is yes, and one of the approaches people developed is *fuzz testing*.

![Log book with computer bug. Source: National Museum of American History, accession number [1994.0191](https://americanhistory.si.edu/collections/search/object/nmah_334663).](/image/log-book-with-computer-bug.jpg)

As the name indicates, fuzz testing focuses on revealing hidden exceptions through the automated generation of a large number of randomized inputs and feeding them to the program (law of large numbers helps). This is especially useful for validating large programs' robustness where the computational components have complex interactions, and the edge cases are tricky to realize. I agree that this description fits the characteristics of some statistical estimation or inference procedures due to their numerical or probabilistic nature.

## Example: fuzz testing oneclust

In R, there is a nice R package [fuzzr](https://cran.r-project.org/package=fuzzr) written by [Matthew Lincoln](https://github.com/mdlincoln). The package offers an example framework for fuzz testing R code. The off-the-shelf functions primarily emphasize the unexpected or non-standard input **types**, while custom tests can be easily created and evaluated.

Let's use it to test my R package [oneclust](https://nanx.me/oneclust/) released in September 2020. The package is built for maximum homogeneity clustering of one-dimensional data. Although the core is implemented in C++ (statically typed), we will see that the R interface still allows some flexibility on input types.

The core function `oneclust::oneclust()` has four arguments:

```
oneclust(x, k, w = NULL, sort = TRUE)
```

where `x` is a numeric vector representing the samples to be clustered, `k` is the number of clusters, `w` is the optional sample weights vector, and `sort` indicates if `x` (and `w`) should be sorted. Example:

```{r}
library("oneclust")

set.seed(42)
x <- sample(c(
  rnorm(50, sd = 0.2),
  rnorm(50, mean = 1, sd = 0.3),
  rnorm(100, mean = -1, sd = 0.25)
))

oneclust(x, 3)
```

Use `fuzzr` to test how argument `x` handles all sorts of input types:

```{r}
library("fuzzr")
library("kableExtra")

f <- fuzz_function(oneclust, "x", k = 3, tests = test_all())
f |>
  as.data.frame() |>
  kbl() |>
  kable_classic(
    lightable_options = c("striped", "hover"),
    html_font = "inherit",
    font_size = 12
  )
```

As expected, we see that the character and data frame inputs did not go through (Not compatible with requested type: [type=...; target=double]). Inputs with empty or NA values also returned index error. The tests that returned meaningful results include `int_multiple`, `dbl_mutliple`, `fctr_multiple`, `fctr_missing_levels`, `lgl_mutliple`, `date_multiple`, `raw_na`, `df_one_col`. It was a bit surprising for me that a factor with missing levels can run here:

```{r}
fuzz_call(f, x = "fctr_missing_levels")
```

It means that a "character factor" like the one below can actually be clustered:

```{r}
oneclust(factor(letters[1:3], levels = letters[1:4]), k = 3)
```

After checking the textbooks, we know that factors in R are built on top of integer vectors, so they were probably treated like one. A deeper understanding of R's vector types helps interpret the other results, too.

Note that we only focused on the input types here. For statistical computing, the exceptions can be caused by subtle numerical issues and strange artifacts in the data, such as the distribution shapes and outliers. In those domain-specific cases, creating your own tests or even frameworks would be helpful.
