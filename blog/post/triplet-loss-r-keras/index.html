<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title> Implementing Triplet Losses for Implicit Feedback Recommender Systems with R and Keras - Nan Xiao | 肖楠 </title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="referrer" content="no-referrer">
    <meta name="description" content="" />

    
    <meta property="og:type" content="article" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:site_name" content="Nan Xiao | 肖楠" />
    <meta property="og:url" content="https://nanx.me/blog/post/triplet-loss-r-keras/" />
    <meta property="og:title" content="Implementing Triplet Losses for Implicit Feedback Recommender Systems with R and Keras" />
    <meta property="og:description" content="" />
    <meta property="og:image" content="https://nanx.me/image/three-palms-jamie-davies.jpg" />
    <meta property="og:image:secure_url" content="https://nanx.me/image/three-palms-jamie-davies.jpg" />
    <meta property="article:published_time" content=" 2018-08-29T19:30:00Z" />
    <meta property="article:modified_time" content=" 2018-08-29T19:30:00Z" />
    <meta property="article:author" content="Nan Xiao" />

    
    <meta name="twitter:card" content="summary_large_image" />
    
    <meta name="twitter:site" content="@nanxstats">
    <meta name="twitter:creator" content="@nanxstats">
    
    <meta name="twitter:title" content="Implementing Triplet Losses for Implicit Feedback Recommender Systems with R and Keras" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:image" content="https://nanx.me/image/three-palms-jamie-davies.jpg" />
    <meta name="twitter:image:alt" content="Implementing Triplet Losses for Implicit Feedback Recommender Systems with R and Keras" />

    
    <meta property="og:linkedin:actor" content="nanxstats" />

    <link rel="canonical" href="https://nanx.me/blog/post/triplet-loss-r-keras/">

    
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        serif: ['"Martina Plantijn"', 'Newsreader', 'Georgia', 'Cambria', '"Times New Roman"', 'Times', 'serif'],
                        sans: ['"Instrument Sans"', 'system-ui', '-apple-system', '"Segoe UI"', 'Roboto', '"Helvetica Neue"', 'Arial', 'sans-serif'],
                        mono: ['"Liga Noto Sans Mono"', 'ui-monospace', 'SFMono-Regular', '"SF Mono"', 'Menlo', 'Consolas', 'monospace'],
                    },
                    colors: {
                        paper: '#fdfdfd',
                        ink: '#1c1c1c',
                        accent: '#991b1b',  
                    },
                    typography: {
                        DEFAULT: {
                            css: {
                                maxWidth: 'none',
                                color: '#1c1c1c',
                                '--tw-prose-body': '#1c1c1c',
                                '--tw-prose-headings': '#1c1c1c',
                                '--tw-prose-links': '#991b1b',
                                '--tw-prose-bold': '#111827',
                                '--tw-prose-counters': '#71717a',
                                '--tw-prose-bullets': '#d4d4d8',
                                '--tw-prose-hr': '#e4e4e7',
                                '--tw-prose-quotes': '#1c1c1c',
                                '--tw-prose-quote-borders': '#d4d4d8',
                                '--tw-prose-captions': '#71717a',
                                '--tw-prose-code': '#1c1c1c',
                                '--tw-prose-pre-code': '#1c1c1c',
                                '--tw-prose-pre-bg': '#fdfdfd',
                                '--tw-prose-th-borders': '#d4d4d8',
                                '--tw-prose-td-borders': '#e4e4e7',
                                'pre': {
                                    color: '#1c1c1c',
                                    backgroundColor: '#fdfdfd !important',
                                    border: '1px solid #e4e4e7',
                                },
                                a: {
                                    color: '#991b1b',
                                    textDecoration: 'none',
                                    fontWeight: '400',
                                    borderBottom: '1px solid transparent',
                                    transition: 'border-color 0.2s ease, color 0.2s ease',
                                },
                                'a:hover': {
                                    color: '#991b1b !important',
                                    borderBottomColor: '#991b1b !important',
                                },
                                h1: { fontFamily: '"Instrument Sans", sans-serif', fontWeight: '500', letterSpacing: '-0.025em' },
                                h2: { fontFamily: '"Instrument Sans", sans-serif', fontWeight: '500', letterSpacing: '-0.025em', marginTop: '2em' },
                                h3: { fontFamily: '"Instrument Sans", sans-serif', fontWeight: '500' },
                                h4: { fontFamily: '"Instrument Sans", sans-serif', fontWeight: '500' },
                                blockquote: {
                                    fontStyle: 'italic',
                                    fontWeight: '400',
                                    borderLeftWidth: '2px',
                                },
                                'code::before': { content: 'none' },
                                'code::after': { content: 'none' },
                                ':not(pre) > code': {
                                    fontWeight: '400',
                                    color: '#1c1c1c !important',
                                    backgroundColor: '#f4f4f5 !important',
                                    padding: '0.2em 0.4em',
                                    borderRadius: '0.25rem',
                                    fontSize: '0.875em',
                                },
                            },
                        },
                    },
                },
            },
        }
    </script>

    <style type="text/tailwindcss">
        @layer utilities {
            .tufte-grid {
                display: grid;
                grid-template-columns: 1fr min(65ch, 100%) 1fr;
                column-gap: 2rem;
            }
            .tufte-grid > * {
                grid-column: 2;
            }
            .tufte-grid > .full-width {
                grid-column: 1 / -1;
            }
            .tufte-grid > .margin-note {
                grid-column: 3;
                font-family: "Instrument Sans", sans-serif;
                font-size: 0.875rem;
                line-height: 1.4;
                color: #52525b;  
                margin-top: 0.25rem;
            }
            @media (max-width: 1024px) {
                .tufte-grid {
                    grid-template-columns: 1rem 1fr 1rem;
                }
                .tufte-grid > .margin-note {
                    grid-column: 2;
                    margin-top: 0.5rem;
                    margin-bottom: 1rem;
                    padding-left: 1rem;
                    border-left: 2px solid #e4e4e7;
                }
            }
        }
    </style>

    <link rel="stylesheet" href="https://nanx.me/css/custom.css" />

    
    <link rel="stylesheet" href="https://nanx.me/css/textmate.css" />
    

    

    <link rel="shortcut icon"
        href="https://nanx.me/image/favicon.png">

    
</head>

<body class="bg-paper text-ink font-serif antialiased selection:bg-zinc-200">
    
<header class="py-8 lg:py-12 text-sm font-sans tracking-wide max-w-[67ch] mx-auto w-full px-4 sm:px-6">
    <div class="flex flex-col sm:flex-row sm:items-center justify-between gap-4 sm:gap-0">
        <a href="https://nanx.me/" class="font-medium text-ink hover:text-accent transition-colors">
            Nan Xiao
        </a>
        <nav class="flex flex-wrap gap-4 sm:gap-6 text-zinc-600">
            
            
            <a class="text-ink font-medium"
                href="https://nanx.me/blog/">
                Blog
            </a>
            
            <a class="hover:text-accent transition-colors"
                href="https://nanx.me/software/">
                Software
            </a>
            
            <a class="hover:text-accent transition-colors"
                href="https://nanx.me/papers/">
                Papers
            </a>
            
            <a class="hover:text-accent transition-colors"
                href="https://nanx.me/talks/">
                Talks
            </a>
            
            <a class="hover:text-accent transition-colors"
                href="https://nanx.me/books/">
                Books
            </a>
            
            <a class="hover:text-accent transition-colors"
                href="https://nanx.me/about/">
                About
            </a>
            
        </nav>
    </div>
</header>

<main class="content my-10 lg:my-20 max-w-[65ch] mx-auto w-full px-4 sm:px-6">
    <article>
        <header class="mb-14">
            <h1 class="text-3xl lg:text-4xl font-sans tracking-tight text-ink font-medium mb-4">Implementing Triplet Losses for Implicit Feedback Recommender Systems with R and Keras</h1>

            <div class="text-zinc-500 font-sans text-sm tracking-wide">
                
                
                <span class="author" title="Nan Xiao">
                    Nan Xiao
                </span>
                
                

                <span class="date middot" title='Wed Aug 29 2018 19:30:00 UTC'>
                    August 29, 2018
                </span>

                <span class="reading-time middot">
                    5 min read
                </span>

                <div class="mt-8 flex flex-wrap gap-2">
                    
                    <a href="https://nanx.me/%20tags/deep-learning"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        deep learning
                    </a>
                    
                    <a href="https://nanx.me/%20tags/triplet-loss"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        triplet loss
                    </a>
                    
                    <a href="https://nanx.me/%20tags/metric-learning"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        metric learning
                    </a>
                    
                    <a href="https://nanx.me/%20tags/recommender-system"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        recommender system
                    </a>
                    
                    <a href="https://nanx.me/%20tags/collaborative-filtering"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        collaborative filtering
                    </a>
                    
                    <a href="https://nanx.me/%20tags/implicit-feedback"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        implicit feedback
                    </a>
                    
                    <a href="https://nanx.me/%20tags/keras"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        Keras
                    </a>
                    
                    <a href="https://nanx.me/%20tags/r"
                        class="inline-flex items-center px-3 py-1 rounded-full bg-zinc-100 text-zinc-600 hover:bg-zinc-200 hover:text-ink transition-colors text-xs font-medium tracking-wide">
                        R
                    </a>
                    
                    
                    
                </div>
            </div>

        </header>

        <div class="prose prose-zinc max-w-none">
            
    
<script src="https://nanx.me/blog/post/triplet-loss-r-keras/index_files/header-attrs/header-attrs.js"></script>


<p>All the R code for this post is available on GitHub: <a href="https://github.com/nanxstats/deep-learning-recipes">nanxstats/deep-learning-recipes</a>.</p>
<div class="figure">
<img src="https://nanx.me/image/three-palms-jamie-davies.jpg" alt="" />
<p class="caption">Photo: <a href="https://unsplash.com/photos/eZt5mvF7RcU">Three Palms</a> by Jamie Davies</p>
</div>
<p>At the end of our <a href="https://nanx.me/blog/post/recsys-binary-implicit-feedback-r-keras/">last post</a>, I briefly mentioned that the triplet loss function is a more proper loss designed for both recommendation problems with implicit feedback data and distance metric learning problems. For its importance in solving these practical problems, and also as an excellent programming exercise, I decided to implement it with R and Keras.</p>
<div id="triplet-loss" class="section level2">
<h2>Triplet Loss</h2>
<p>The triplet loss makes us focus on the core of many supervised/unsupervised learning problems: learning better representations for data. The idea is pretty simple: we want to learn a custom distance metric or (low-rank) representation for our data, such that under this new metric or representation, the distance between “similar” observations is smaller, and the distance between “dissimilar” observations is larger. Here the definition of “similar” or “dissimilar” observations may come from some side information.</p>
<p>The idea of learning a global Mahalanobis distance metric was first formalized by <a href="https://dl.acm.org/doi/10.5555/2968618.2968683">Xing et al.</a> as a convex optimization problem. The <a href="https://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf">LMNN by Weinberger and Saul</a> is the work that first formulated the metric learning problem as a localized large margin learning problem with “triplets”, partially inspired by the SVM objective function. The triplet loss was further popularized by the <a href="https://arxiv.org/abs/1503.03832">FaceNet by Schroff et al.</a> in the computer vision and especially the face recognition community. A margin-based triplet loss function looks like this:</p>
<p><span class="math display">\[L_\text{margin}(a, p, n) = \sum \max(0, f(a, p) - f(a, n) + \varepsilon)\]</span></p>
<p>where <span class="math inline">\(a\)</span> is an “anchor” observation. <span class="math inline">\(p\)</span> is the “positive” sample which should be closer to <span class="math inline">\(a\)</span> than the “negative” sample <span class="math inline">\(n\)</span>. We will need many such triplets <span class="math inline">\(\{a, p, n\}\)</span>. <span class="math inline">\(f\)</span> is the transformation we want to learn. <span class="math inline">\(\varepsilon\)</span> is a constant number larger than zero (tuning parameter). A natural interpretation of the loss function: the learned metric should separate the negative sample <span class="math inline">\(n\)</span> from the positive sample <span class="math inline">\(n\)</span> at least by a positive margin <span class="math inline">\(\varepsilon\)</span>.</p>
</div>
<div id="data-and-model" class="section level2">
<h2>Data and Model</h2>
<p>To make things easier to understand, this time we will use the MovieLens data as the example. Naturally, we will also use the jargon of users/items to denote the two parties presented in a recommender system.</p>
<p>We binarized the 1 to 5 ratings to make it binary (interacting or non-interacting user-item pairs) implicit feedback data. To construct the triplets, we sample from the interacting user-items pairs and combine them with randomly sampled non-interaction items for the users.</p>
<p>The model looks like this:</p>
<div class="figure">
<img src="triplet-loss-model-keras.png" alt="" />
<p class="caption">Figure: A barebone matrix factorization model with a triplet loss for recommender systems with implicit feedback data.</p>
</div>
<p>From the figure, the low-rank, dense embeddings for users and items are the inputs for the loss function (the Lambda layer). By minimizing the loss function, we achieved our goal: learning representations for users and items. Note that the embedding layer for items is shared by the positive and negative items since they are inherently both items thus should use the same representation.</p>
</div>
<div id="implementation" class="section level2">
<h2>Implementation</h2>
<p>Unlike our <a href="https://nanx.me/blog/post/recsys-binary-implicit-feedback-r-keras/">last post</a> which modeled this as a classification problem, we don’t have the “labels” in the traditional sense here. Instead, the training loss itself will be the output as is shown above. Therefore, it is a little tricky to implement this with Keras because we need to build a custom loss function, build a custom metric function, and finally, build a custom prediction function. This is precisely why it would be a good programming exercise.</p>
<p>The closest <a href="https://github.com/maciejkula/triplet_recommendations_keras">reference implementation</a> I could find is written in Python. Unfortunately, the code is a bit outdated and doesn’t play well with the latest Keras API. So I reimplemented the model in R and made it running on the latest Keras and Tensorflow backend successfully, with the help of the functional style <a href="https://keras.io/api/layers/core_layers/lambda/">lambda layers</a>.</p>
</div>
<div id="performance-evaluation" class="section level2">
<h2>Performance Evaluation</h2>
<p>The custom performance metric we implemented is a user-averaged AUC. In essence, for each user in the test set, we predict the probability if an item will be preferred by the user on all items in the test set. We then compute the AUC based on these predictions for this user, do this for all users, and average all the AUC values. Intuitively, this metric can roughly reflect the probability that a randomly selected positive item will be ranked higher than a randomly selected negative item for users.</p>
<p>The loss and AUC change on the training/test set is visualized below.</p>
<div class="figure">
<img src="triplet-loss-margin-movielens.png" alt="" />
<p class="caption">Figure: The first 20 epochs: loss and user-averaged AUC for the margin-based triplet loss model.</p>
</div>
</div>
<div id="the-bpr-triplet-loss" class="section level2">
<h2>The BPR Triplet Loss</h2>
<p>What our reference implementation had is another type of triplet loss, namely, the <a href="https://arxiv.org/abs/1205.2618">Bayesian Personalized Ranking (BPR) loss</a>:</p>
<p><span class="math display">\[L_\text{BPR}(a, p, n) = \sum \big(1 - \sigma(f(a, p) - f(a, n)) \big)\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the sigmoid function. For the sake of completeness, I also implemented it. It has a strikingly similar performance to the margin-based model for our data here, while it converges faster with the benefit of not needing to tune the margin parameter of the loss.</p>
<div class="figure">
<img src="triplet-loss-bpr-movielens.png" alt="" />
<p class="caption">Figure: The first 20 epochs: loss and user-averaged AUC for the BPR triplet loss model.</p>
</div>
</div>
<div id="comments" class="section level2">
<h2>Comments</h2>
<p><strong>Hard negative mining.</strong> A crucial aspect for improving the performance of models with a triplet loss is about selecting or constructing more hard-to-learn triplets which can help you learn the representations or metrics better. This is often called the “hard negative mining” problem. The <a href="https://arxiv.org/abs/1503.03832">FaceNet paper</a> described their triplet selection approach. Here is also a <a href="https://omoindrot.github.io/triplet-loss">good post</a> explaining more details on this.</p>
<p><strong>Applications.</strong> The bar of applying this method is relatively low because sometimes the required data is more accessible than fully labeled data. Conceptually, this idea can be applied to any learning problems where we can construct the triplets. An extreme case is the recsys with implicit feedback data we just showed: we only know the relative preference between entities (e.g., user’s relative preference for items). The more common scenarios are where the true labels of data are difficult to get, but one might know the distance/similarity relationships between entities (images, text, human genomes).</p>
</div>



        </div>

        
        <nav class="pagination-nav mt-10 mb-3" aria-label="Blog post navigation">
            <div class="navigation-btns">
                
                <a href="https://nanx.me/blog/post/how-a-financial-crisis-started/" class="btn-nav btn-prev w-full">
                    <div class="btn-content">
                        <div class="pagination-nav-sublabel">Previous</div>
                        <div class="pagination-nav-label">&laquo; How a Financial Crisis Started</div>
                    </div>
                </a>
                

                
                <a href="https://nanx.me/blog/post/accidental-product-success/" class="btn-nav btn-next w-full">
                    <div class="btn-content">
                        <div class="pagination-nav-sublabel">Next</div>
                        <div class="pagination-nav-label">The Accidental Product Success &raquo;</div>
                    </div>
                </a>
                
            </div>
        </nav>
        

    </article>
</main>

<section id="comments">
    <div class="py-3 content">
        <div class="mx-auto max-w-[65ch] w-full px-4 sm:px-6">
            <div class="comments">
                <script src="https://utteranc.es/client.js" repo="nanxstats/blog-comments" issue-term="pathname"
                    label="comment" theme="github-light" crossorigin="anonymous" async>
                    </script>
            </div>
        </div>
    </div>
</section>
<footer class="mt-20 mb-10 text-center font-sans text-sm text-zinc-500 tracking-wide">
    <div class="tufte-grid">
        <div class="flex flex-col items-center gap-4">
            <div class="flex flex-wrap items-center justify-center gap-x-4 gap-y-2">
                
                
                <a href="https://github.com/nanxstats" target="_blank" rel="noopener"
                    class="hover:text-accent transition-colors">GitHub</a>
                
                
                
                
                <a href="https://www.linkedin.com/in/nanxstats" target="_blank" rel="noopener"
                    class="hover:text-accent transition-colors">LinkedIn</a>
                
                
                <a href="https://bsky.app/profile/nanxstats.bsky.social" target="_blank" rel="noopener"
                    class="hover:text-accent transition-colors">Bluesky</a>
                
                
                <a href="https://twitter.com/nanxstats" target="_blank" rel="noopener"
                    class="hover:text-accent transition-colors">Twitter</a>
                
                
                
                <a href="https://nanx.me/colophon/" class="hover:text-accent transition-colors">Colophon</a>
                
                
            </div>

            
            <div class="mt-2">
                © 2026 Nan Xiao. All rights reserved.
            </div>
            
        </div>
    </div>
</footer>


    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"
        integrity="sha512-EBLzUL8XLl+va/zAsmXwS7Z2B1F9HUHkZwyS/VKwh3S7T/U0nF4BaU29EP/ZSf6zgiIxYAnKLu6bJ8dqpmX5uw=="
        crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/r.min.js" defer></script>
    
    <script>
        window.addEventListener('load', function () {
            hljs.highlightAll();
        }, true);
    </script>
    

    

    
    
    
<script src="https://nanx.me/js/math-code.js"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
</body>

</html>